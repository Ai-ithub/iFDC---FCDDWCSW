{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ2vJ7xjI1XH",
        "outputId": "a57d5d7d-dbf7-401a-b4bf-ac22a977c006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Mounted at /content/drive\n",
            "✅ دیتاست با موفقیت خوانده شد.\n",
            "🔢 ستون‌های عددی شناسایی شده: ['Temperature_C', 'Pressure_psi', 'pH', 'Salinity_ppm', 'Flow_Rate_bbl_day', 'Permeability_mD', 'Porosity_pct']\n",
            "✅ پارامترهای نرمال‌سازی ذخیره شدند.\n",
            "✅ داده نرمال‌سازی‌شده ذخیره شد.\n"
          ]
        }
      ],
      "source": [
        "# --- مرحله 1: نصب وابستگی‌ها ---\n",
        "!pip install pandas pyarrow scikit-learn joblib\n",
        "\n",
        "# --- مرحله 2: متصل شدن به Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- مرحله 3: خواندن دیتاست با مدیریت خطا ---\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "file_path = '/content/drive/MyDrive/formation_damage_optimized.parquet'\n",
        "\n",
        "try:\n",
        "    # سعی در خواندن فایل Parquet\n",
        "    df = pd.read_parquet(file_path)\n",
        "    print(\"✅ دیتاست با موفقیت خوانده شد.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ فایل دیتاست یافت نشد. دیتای تست مصنوعی تولید می‌شود...\")\n",
        "    # تولید دیتای تست مصنوعی (در صورت نبود فایل)\n",
        "    from generate_synthetic_data import generate_data\n",
        "    df = generate_data(n_samples=1000)\n",
        "    df.to_parquet('formation_damage_optimized.parquet')\n",
        "    print(\"✅ دیتای تست مصنوعی ذخیره شد.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ خطای غیرمنتظره: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- مرحله 4: شناسایی ستون‌های عددی ---\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "print(\"🔢 ستون‌های عددی شناسایی شده:\", numeric_cols)\n",
        "\n",
        "# --- مرحله 5: نرمال‌سازی و ذخیره پارامترها ---\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import joblib\n",
        "\n",
        "scalers = {}\n",
        "normalized_df = df.copy()\n",
        "\n",
        "for col in numeric_cols:\n",
        "    # تعیین روش نرمال‌سازی (مثال: Min-Max برای مقادیر محدود، Z-Score برای توزیع نرمال)\n",
        "    if df[col].min() >= 0 and df[col].max() <= 1000:\n",
        "        scaler = MinMaxScaler()\n",
        "        normalized_df[col] = scaler.fit_transform(df[[col]])\n",
        "        scalers[col] = {\n",
        "            'type': 'MinMax',\n",
        "            'min': scaler.data_min_[0],\n",
        "            'max': scaler.data_max_[0]\n",
        "        }\n",
        "    else:\n",
        "        scaler = StandardScaler()\n",
        "        normalized_df[col] = scaler.fit_transform(df[[col]])\n",
        "        scalers[col] = {\n",
        "            'type': 'Standard',\n",
        "            'mean': scaler.mean_[0],\n",
        "            'std': scaler.scale_[0]\n",
        "        }\n",
        "\n",
        "# ذخیره اسکیلرهای آموزش دیده\n",
        "joblib.dump(scalers, 'scalers_params.joblib')\n",
        "print(\"✅ پارامترهای نرمال‌سازی ذخیره شدند.\")\n",
        "\n",
        "# --- مرحله 6: ذخیره داده نرمال‌سازی‌شده ---\n",
        "normalized_df.to_parquet('normalized_formation_damage.parquet')\n",
        "print(\"✅ داده نرمال‌سازی‌شده ذخیره شد.\")\n",
        "\n"
      ]
    }
  ]
}