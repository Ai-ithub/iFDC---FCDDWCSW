# -*- coding: utf-8 -*-
"""Untitled28.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/119XgobXuZc1ellToLn0P8iDu0No0VOeY
"""

#from google.colab import drive
#drive.mount('/content/mydrive')

#!pip install pandas pyarrow
#!pip install pandas fastparquet

import pandas as pd
import numpy as np
# -------------------------------
# 1. خواندن فایل Parquet
# -------------------------------
file_path = './datasets/formation_damage_optimized.parquet'  # نام فایل ورودی
df = pd.read_parquet(file_path)

# -------------------------------
# 2. تعریف ستون‌های مورد نظر
# -------------------------------
columns_to_clean = ['Damage_Type', 'Formation', 'Fluid_Type', 'Completion_Type']

# -------------------------------
# 3. تابع یکنواخت‌سازی داده‌های متنی
# -------------------------------
def standardize_text(text):
    if isinstance(text, str):
        return text.strip().lower()
    else:
        return text

# -------------------------------
# 4. جدول معادل‌های املایی (غلط -> درست)
# -------------------------------
text_corrections = {
    'frac': 'fracture',
    'acid': 'acidizing',
    'gas': 'gas lift',
    'beam': 'pump',
    'horiz': 'horizontal',
    'vert': 'vertical',
    'water': 'water',
    'oil': 'oil',
    'scale': 'scale',
    'limestone': 'limestone',
    'sandstone': 'sandstone'
}

# -------------------------------
# 5. تابع اعمال اصلاحات
# -------------------------------
def correct_text(value):
    value = standardize_text(value)
    return text_corrections.get(value, value)  # اگر در جدول باشد، جایگزین کن

# -------------------------------
# 6. اعمال یکنواخت‌سازی روی ستون‌های مورد نظر
# -------------------------------
for col in columns_to_clean:
    df[col] = df[col].apply(correct_text)

# -------------------------------
# 7. استخراج مقادیر یکتا (Unique Values) از هر ستون
# -------------------------------
unique_values = {}

for col in columns_to_clean:
    unique_vals = df[col].dropna().unique()
    unique_values[col] = sorted(unique_vals)

# -------------------------------
# 8. ذخیره مقادیر یکتا در یک فایل CSV برای بررسی کیفیت
# -------------------------------
output_file = './datasets/unique_values_report.csv'

with open(output_file, 'w', encoding='utf-8') as f:
    for col, values in unique_values.items():
        f.write(f"Column: {col}\n")
        for val in values:
            f.write(f"{val}\n")
        f.write("\n")

print(f"✅ مقادیر یکتا در فایل '{output_file}' ذخیره شدند.")
# -------------------------------
# 9. (اختیاری) ذخیره دیتافریم پاک‌شده در فایل parquet جدید
# -------------------------------
cleaned_file = './datasets/text_corrected_data.parquet'
df.to_parquet(cleaned_file, index=False)
print(f"✅ داده‌های پاک‌شده در فایل '{cleaned_file}' ذخیره شدند.")